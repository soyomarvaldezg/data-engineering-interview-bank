# PySpark en Entrevistas de Data Engineering

## ¿Por qué PySpark?

PySpark es el **framework más usado** en data engineering.
Esperan que entiendas:

- RDD vs DataFrame
- Transformations & Actions
- Lazy evaluation
- Optimization & Caching
- Partitioning

## Temas cubiertos

1. RDD vs DataFrame (¿Cuándo usar cada uno?)
2. Transformations & Actions (map, filter, reduce, etc.)
3. Optimization & Caching Strategies
4. Performance Tuning
